{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1836927",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data source: https://www.kaggle.com/datasets/kaushiksuresh147/customer-segmentation\n",
    "\n",
    "I applied the techniques we learn in the class to classify customers. There are \n",
    "4 type of customers given in this data set. Success rate seems very low. To remedy\n",
    "I  compared results when same data cleaning methods from Kaggle users are applied.\n",
    "However, there seem to be not much progresss. Most users have success rate around\n",
    "50%. There is one .99 solution, which I checked also, gives %45 sucess rate \n",
    "'''\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f3e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329ce31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv(\"Train.csv\")\n",
    "df_te = pd.read_csv(\"Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6427cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09cc35e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>464018</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>464685</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>35</td>\n",
       "      <td>No</td>\n",
       "      <td>Executive</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8065</th>\n",
       "      <td>465406</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>33</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8066</th>\n",
       "      <td>467299</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>27</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>461879</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Executive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8068 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Gender Ever_Married  Age Graduated     Profession  \\\n",
       "0     462809    Male           No   22        No     Healthcare   \n",
       "1     462643  Female          Yes   38       Yes       Engineer   \n",
       "2     466315  Female          Yes   67       Yes       Engineer   \n",
       "3     461735    Male          Yes   67       Yes         Lawyer   \n",
       "4     462669  Female          Yes   40       Yes  Entertainment   \n",
       "...      ...     ...          ...  ...       ...            ...   \n",
       "8063  464018    Male           No   22        No            NaN   \n",
       "8064  464685    Male           No   35        No      Executive   \n",
       "8065  465406  Female           No   33       Yes     Healthcare   \n",
       "8066  467299  Female           No   27       Yes     Healthcare   \n",
       "8067  461879    Male          Yes   37       Yes      Executive   \n",
       "\n",
       "      Work_Experience Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0                 1.0            Low          4.0  Cat_4            D  \n",
       "1                 NaN        Average          3.0  Cat_4            A  \n",
       "2                 1.0            Low          1.0  Cat_6            B  \n",
       "3                 0.0           High          2.0  Cat_6            B  \n",
       "4                 NaN           High          6.0  Cat_6            A  \n",
       "...               ...            ...          ...    ...          ...  \n",
       "8063              0.0            Low          7.0  Cat_1            D  \n",
       "8064              3.0            Low          4.0  Cat_4            D  \n",
       "8065              1.0            Low          1.0  Cat_6            D  \n",
       "8066              1.0            Low          4.0  Cat_6            B  \n",
       "8067              0.0        Average          3.0  Cat_4            B  \n",
       "\n",
       "[8068 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba0ade6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>458989</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>36</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>458994</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458996</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>69</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459000</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>59</td>\n",
       "      <td>No</td>\n",
       "      <td>Executive</td>\n",
       "      <td>11.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459001</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>19</td>\n",
       "      <td>No</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>467954</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>29</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>467958</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>35</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>467960</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>53</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>467961</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>47</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Executive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>467968</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>43</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_7</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2627 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Gender Ever_Married  Age Graduated     Profession  \\\n",
       "0     458989  Female          Yes   36       Yes       Engineer   \n",
       "1     458994    Male          Yes   37       Yes     Healthcare   \n",
       "2     458996  Female          Yes   69        No            NaN   \n",
       "3     459000    Male          Yes   59        No      Executive   \n",
       "4     459001  Female           No   19        No      Marketing   \n",
       "...      ...     ...          ...  ...       ...            ...   \n",
       "2622  467954    Male           No   29        No     Healthcare   \n",
       "2623  467958  Female           No   35       Yes         Doctor   \n",
       "2624  467960  Female           No   53       Yes  Entertainment   \n",
       "2625  467961    Male          Yes   47       Yes      Executive   \n",
       "2626  467968  Female           No   43       Yes     Healthcare   \n",
       "\n",
       "      Work_Experience Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0                 0.0            Low          1.0  Cat_6            B  \n",
       "1                 8.0        Average          4.0  Cat_6            A  \n",
       "2                 0.0            Low          1.0  Cat_6            A  \n",
       "3                11.0           High          2.0  Cat_6            B  \n",
       "4                 NaN            Low          4.0  Cat_6            A  \n",
       "...               ...            ...          ...    ...          ...  \n",
       "2622              9.0            Low          4.0  Cat_6            B  \n",
       "2623              1.0            Low          1.0  Cat_6            A  \n",
       "2624              NaN            Low          2.0  Cat_6            C  \n",
       "2625              1.0           High          5.0  Cat_4            C  \n",
       "2626              9.0            Low          3.0  Cat_7            A  \n",
       "\n",
       "[2627 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9558676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ffaf1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   0\n",
       "Gender               0\n",
       "Ever_Married        50\n",
       "Age                  0\n",
       "Graduated           24\n",
       "Profession          38\n",
       "Work_Experience    269\n",
       "Spending_Score       0\n",
       "Family_Size        113\n",
       "Var_1               32\n",
       "Segmentation         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_te.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb3a74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_tr,df_te])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3ad0691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10695 entries, 0 to 10694\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               10695 non-null  int64  \n",
      " 1   Gender           10695 non-null  object \n",
      " 2   Ever_Married     10505 non-null  object \n",
      " 3   Age              10695 non-null  int64  \n",
      " 4   Graduated        10593 non-null  object \n",
      " 5   Profession       10533 non-null  object \n",
      " 6   Work_Experience  9597 non-null   float64\n",
      " 7   Spending_Score   10695 non-null  object \n",
      " 8   Family_Size      10247 non-null  float64\n",
      " 9   Var_1            10587 non-null  object \n",
      " 10  Segmentation     10695 non-null  object \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 919.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f24b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ID'], axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56685714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Gender'].unique()\n",
    "g = {'Male':1, 'Female':0}\n",
    "df['Gender'] = df['Gender'].map(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d87b18b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', nan], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ever_Married'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74418c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    0.586673\n",
       "No     0.413327\n",
       "Name: Ever_Married, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ever_Married'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f167cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Ever_Married'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be6ab088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since house is almost equally likely to have one type for basements of TA\n",
    "# and Gd, we fill empty rows randomly either TA or Gd\n",
    "import random\n",
    "random.uniform(0, 1)\n",
    "def set_marital_status(self) :\n",
    "    x = random.uniform(0, 1)\n",
    "    if x > 0.59 :\n",
    "        return 'Yes'\n",
    "    else: \n",
    "        return 'No'\n",
    "    \n",
    "df['Ever_Married'].fillna(df['Ever_Married'].apply(set_marital_status), inplace=True) \n",
    "\n",
    "g = {'Yes':1, 'No':0}\n",
    "df['Ever_Married'] = df['Ever_Married'].map(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7a45d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10695 entries, 0 to 10694\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Gender           10695 non-null  int64  \n",
      " 1   Ever_Married     10695 non-null  int64  \n",
      " 2   Age              10695 non-null  int64  \n",
      " 3   Graduated        10593 non-null  object \n",
      " 4   Profession       10533 non-null  object \n",
      " 5   Work_Experience  9597 non-null   float64\n",
      " 6   Spending_Score   10695 non-null  object \n",
      " 7   Family_Size      10247 non-null  float64\n",
      " 8   Var_1            10587 non-null  object \n",
      " 9   Segmentation     10695 non-null  object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 835.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62c9b3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', nan], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Graduated'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73dc844e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Healthcare', 'Engineer', 'Lawyer', 'Entertainment', 'Artist',\n",
       "       'Executive', 'Doctor', 'Homemaker', 'Marketing', nan], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Profession'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d968a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['column_1'] = df['column_1'].fillna('yes' if condition else df['column_1'])\n",
    "#condition = df['Profession'] == 'Engineer' or df['Profession'] == 'Lawyer' or \\\n",
    "#df['Profession'] == 'Executive' or df['Profession'] == 'Doctor'\n",
    "\n",
    "#condition = df['Profession'].isin(['Engineer', 'Lawyer', 'Executive', 'Doctor'])\n",
    "#condition = df['Profession'] == 'Engineer'\n",
    "#df['Graduated'] = df['Graduated'].fillna('Yes' if df['Profession'] == 'Doctor' else df['Graduated'])\n",
    "\n",
    "df['Graduated'] = np.where(df['Profession'] == 'Engineer','Yes', df['Graduated'])\n",
    "df['Graduated'] = np.where(df['Profession'] == 'Lawyer','Yes', df['Graduated'])\n",
    "df['Graduated'] = np.where(df['Profession'] == 'Executive','Yes', df['Graduated'])\n",
    "df['Graduated'] = np.where(df['Profession'] == 'Doctor','Yes', df['Graduated'])\n",
    "\n",
    "df['Graduated'] = df['Graduated'].fillna('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "583187cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10695 entries, 0 to 10694\n",
      "Series name: Graduated\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10695 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df['Graduated'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16d8a97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Profession'] = np.where(df['Profession']  ,'Self-employed', df['Profession'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29fc7cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10695 entries, 0 to 10694\n",
      "Series name: Profession\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10533 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df['Profession'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca9ac22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Profession'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc6b70fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Profession'] = df['Profession'].fillna( 'Artist' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7a5a470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10695 entries, 0 to 10694\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Gender           10695 non-null  int64  \n",
      " 1   Ever_Married     10695 non-null  int64  \n",
      " 2   Age              10695 non-null  int64  \n",
      " 3   Graduated        10695 non-null  object \n",
      " 4   Profession       10695 non-null  object \n",
      " 5   Work_Experience  9597 non-null   float64\n",
      " 6   Spending_Score   10695 non-null  object \n",
      " 7   Family_Size      10247 non-null  float64\n",
      " 8   Var_1            10587 non-null  object \n",
      " 9   Segmentation     10695 non-null  object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 835.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2a74bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
       "       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1',\n",
       "       'Segmentation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47567b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\users\\haluk\\appdata\\roaming\\python\\python311\\site-packages (2.0.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f998563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work experience estimation\n",
    "x = df[ ['Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
    "        'Spending_Score', 'Segmentation'] ]\n",
    "x = pd.get_dummies(x,drop_first = True)\n",
    "\n",
    "\n",
    "test_indices = df[ df['Work_Experience'].isnull() ].index\n",
    "y_train = df['Work_Experience'].drop(test_indices)\n",
    "x_test    = x.loc[test_indices]\n",
    "x_train   = x.drop(test_indices)\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "xgb=XGBRegressor()\n",
    "XGBC= XGBRegressor()\n",
    "model=XGBC.fit(x_train,y_train)\n",
    "pred=model.predict(x_test)\n",
    "\n",
    "y_pred_xgb = model.predict(x_test)\n",
    "df.loc[df['Work_Experience'].isnull(), 'Work_Experience'] = y_pred_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf969e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9597, 17), (9597,), (1098, 17))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "452e2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family size estimation\n",
    "x = df[ ['Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
    "        'Spending_Score', 'Segmentation', 'Work_Experience'] ]\n",
    "x = pd.get_dummies(x,drop_first = True)\n",
    "\n",
    "\n",
    "test_indices = df[ df['Family_Size'].isnull() ].index\n",
    "y_train = df['Family_Size'].drop(test_indices)\n",
    "x_test    = x.loc[test_indices]\n",
    "x_train   = x.drop(test_indices)\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "xgb=XGBRegressor()\n",
    "XGBC= XGBRegressor()\n",
    "model=XGBC.fit(x_train,y_train)\n",
    "pred=model.predict(x_test)\n",
    "\n",
    "y_pred_xgb = model.predict(x_test)\n",
    "df.loc[df['Family_Size'].isnull(), 'Family_Size'] = y_pred_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1140f9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Var_1'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81fcb104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Var_1'] = df['Var_1'].fillna( 'Cat_6' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "695812d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = {'A':0, 'B':1, 'C':2, 'D':3 }\n",
    "#cat = {'A':1, 'B':2, 'C':3, 'D':4 }\n",
    "df['Segmentation'].unique()\n",
    "df['Segmentation'] = df['Segmentation'].map(cat) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56c315db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
       "       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1',\n",
       "       'Segmentation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81ab5c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
    "       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1']]\n",
    "\n",
    "#x = df[['Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
    "#       'Work_Experience', 'Spending_Score', 'Family_Size']]\n",
    "\n",
    "y = df['Segmentation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ce15b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10695 entries, 0 to 10694\n",
      "Series name: Segmentation\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10695 non-null  int32\n",
      "dtypes: int32(1)\n",
      "memory usage: 41.9 KB\n"
     ]
    }
   ],
   "source": [
    "y = y.astype(int)\n",
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20c044c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.get_dummies(x, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aeaedd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8068, 22), (2627, 22), (8068,), (2627,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x[:8068]\n",
    "x_test = x[8068:]\n",
    "y_train = y[:8068]\n",
    "y_test = y[8068:]\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b571af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67ffcdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_test(x,y):\n",
    "def algo_test(x_train,x_test,y_train,y_test):\n",
    "    \n",
    "    import numpy as np\n",
    "\n",
    "    from scipy import stats\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline \n",
    "    import seaborn as sns\n",
    "\n",
    "\n",
    "    from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "    from sklearn.linear_model import LinearRegression, ElasticNet, Ridge, Lasso\n",
    "    from sklearn.tree import ExtraTreeClassifier\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    from xgboost import XGBRegressor \n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.ensemble import ExtraTreesClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "#plt.style.use('')\n",
    "\n",
    "    \n",
    "    \n",
    "    G = GaussianNB()\n",
    "    B = BernoulliNB()\n",
    "    #K = KNeighborsClassifier()\n",
    "    L = LogisticRegression()\n",
    "    D = DecisionTreeClassifier()\n",
    "    RF = RandomForestClassifier()\n",
    "    ETC = ExtraTreesClassifier()\n",
    "    XG = XGBClassifier()\n",
    "\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state = 13)\n",
    "    \n",
    "    algos = [G,B,L,D, RF, ETC, XG]\n",
    "    #algos = [G,B,L,D,  RF, ETC]\n",
    "    \n",
    "    #algo_names = [ \"Gaussian\", \"Bernoulli\", \"K-Neighbors\", \"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"ExtraTreeClassifier\" ]\n",
    "    algo_names = [ \"Gaussian\", \"Bernoulli\", \"Logistic Regression\", \"Decision Tree\", \\\n",
    "                  \"Random Forest\", \"ExtraTreeClassifier\",\"XGBClassifier\" ]\n",
    "    \n",
    "    ASC = [];\n",
    "    \n",
    "    result =  result = pd.DataFrame(columns =['Accuracy_Score'], index = algo_names)\n",
    "    \n",
    "    i = 0;\n",
    "    for algo in algos :\n",
    "        \n",
    "        algo.fit(x_train,y_train)\n",
    "        #print (accuracy_score(  y_test, algo.predict(x_test) ))\n",
    "        ASC.append(  accuracy_score(  y_test, algo.predict(x_test) ) )\n",
    "        \n",
    "        print( \"Confusion matrix: \",format(algo_names[i]) )\n",
    "        i = i+1;\n",
    "        print ( confusion_matrix(algo.predict(x_test),y_test) )\n",
    "        #print (classification_report(y_test,algo.predict(x_test) ))\n",
    "        \n",
    "        #algo.fit(x,y)\n",
    "        #print (accuracy_score(  y, algo.predict(x) ))\n",
    "        #ASC.append(  accuracy_score(  y, algo.predict(x) ) )\n",
    "    \n",
    "    \n",
    "    result.Accuracy_Score = ASC;\n",
    "\n",
    "    return result.sort_values('Accuracy_Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2a99049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:  Gaussian\n",
      "[[196 135  66 135]\n",
      " [ 31  54  45  20]\n",
      " [190 239 320 107]\n",
      " [122  65  63 351]]\n",
      "Confusion matrix:  Bernoulli\n",
      "[[161 120  56 120]\n",
      " [ 34  45  41  23]\n",
      " [156 212 306  93]\n",
      " [188 116  91 377]]\n",
      "Confusion matrix:  Logistic Regression\n",
      "[[297 220 120 190]\n",
      " [ 35  39  37  16]\n",
      " [108 183 283  71]\n",
      " [ 99  51  54 336]]\n",
      "Confusion matrix:  Decision Tree\n",
      "[[202 150 101 178]\n",
      " [121 127 129  77]\n",
      " [102 121 204  79]\n",
      " [114  95  60 279]]\n",
      "Confusion matrix:  Random Forest\n",
      "[[214 140  82 129]\n",
      " [114 134 121  66]\n",
      " [ 93 124 222  61]\n",
      " [118  95  69 357]]\n",
      "Confusion matrix:  ExtraTreeClassifier\n",
      "[[213 138  85 150]\n",
      " [120 127 124  60]\n",
      " [ 88 129 220  71]\n",
      " [118  99  65 332]]\n",
      "Confusion matrix:  XGBClassifier\n",
      "[[240 131  79 154]\n",
      " [102 140  97  60]\n",
      " [ 75 141 261  45]\n",
      " [122  81  57 354]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.465171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.446470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.433380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian</th>\n",
       "      <td>0.430575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.417017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli</th>\n",
       "      <td>0.415615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.379617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy_Score\n",
       "XGBClassifier              0.465171\n",
       "Logistic Regression        0.446470\n",
       "Random Forest              0.433380\n",
       "Gaussian                   0.430575\n",
       "ExtraTreeClassifier        0.417017\n",
       "Bernoulli                  0.415615\n",
       "Decision Tree              0.379617"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_test(x_train,x_test,y_train,y_test)\n",
    "#algo_test(x,y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7fe2573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.2945 - accuracy: 0.3985 - val_loss: 1.1884 - val_accuracy: 0.4684\n",
      "Epoch 2/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.1695 - accuracy: 0.4721 - val_loss: 1.1575 - val_accuracy: 0.4783\n",
      "Epoch 3/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.1381 - accuracy: 0.4905 - val_loss: 1.1217 - val_accuracy: 0.5074\n",
      "Epoch 4/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.1232 - accuracy: 0.4926 - val_loss: 1.1216 - val_accuracy: 0.5031\n",
      "Epoch 5/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.1078 - accuracy: 0.4981 - val_loss: 1.1201 - val_accuracy: 0.4988\n",
      "Epoch 6/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0997 - accuracy: 0.5115 - val_loss: 1.1044 - val_accuracy: 0.4994\n",
      "Epoch 7/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0900 - accuracy: 0.5127 - val_loss: 1.0869 - val_accuracy: 0.5062\n",
      "Epoch 8/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0962 - accuracy: 0.5053 - val_loss: 1.0860 - val_accuracy: 0.5099\n",
      "Epoch 9/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0810 - accuracy: 0.5161 - val_loss: 1.1121 - val_accuracy: 0.5056\n",
      "Epoch 10/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.0816 - accuracy: 0.5132 - val_loss: 1.0859 - val_accuracy: 0.5056\n",
      "Epoch 11/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0779 - accuracy: 0.5160 - val_loss: 1.0989 - val_accuracy: 0.4957\n",
      "Epoch 12/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0743 - accuracy: 0.5218 - val_loss: 1.1000 - val_accuracy: 0.4950\n",
      "Epoch 13/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0718 - accuracy: 0.5181 - val_loss: 1.0818 - val_accuracy: 0.5124\n",
      "Epoch 14/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0674 - accuracy: 0.5205 - val_loss: 1.0975 - val_accuracy: 0.4864\n",
      "Epoch 15/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0625 - accuracy: 0.5271 - val_loss: 1.0972 - val_accuracy: 0.5112\n",
      "Epoch 16/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0622 - accuracy: 0.5187 - val_loss: 1.0843 - val_accuracy: 0.5143\n",
      "Epoch 17/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0583 - accuracy: 0.5259 - val_loss: 1.0892 - val_accuracy: 0.5025\n",
      "Epoch 18/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0532 - accuracy: 0.5222 - val_loss: 1.0770 - val_accuracy: 0.5155\n",
      "Epoch 19/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0484 - accuracy: 0.5288 - val_loss: 1.0923 - val_accuracy: 0.5173\n",
      "Epoch 20/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.0551 - accuracy: 0.5254 - val_loss: 1.0804 - val_accuracy: 0.5186\n",
      "Epoch 21/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.0555 - accuracy: 0.5256 - val_loss: 1.0804 - val_accuracy: 0.5211\n",
      "Epoch 22/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.0454 - accuracy: 0.5328 - val_loss: 1.0818 - val_accuracy: 0.4969\n",
      "Epoch 23/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.0420 - accuracy: 0.5327 - val_loss: 1.0827 - val_accuracy: 0.5143\n",
      "Epoch 24/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0397 - accuracy: 0.5330 - val_loss: 1.0816 - val_accuracy: 0.5068\n",
      "Epoch 25/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.0430 - accuracy: 0.5268 - val_loss: 1.0803 - val_accuracy: 0.5192\n",
      "Epoch 26/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.0353 - accuracy: 0.5294 - val_loss: 1.1213 - val_accuracy: 0.5074\n",
      "Epoch 27/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.0341 - accuracy: 0.5347 - val_loss: 1.0844 - val_accuracy: 0.5180\n",
      "Epoch 28/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.0325 - accuracy: 0.5378 - val_loss: 1.0807 - val_accuracy: 0.5112\n",
      "Epoch 29/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.0259 - accuracy: 0.5367 - val_loss: 1.0868 - val_accuracy: 0.5012\n",
      "Epoch 30/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0275 - accuracy: 0.5420 - val_loss: 1.0889 - val_accuracy: 0.5173\n",
      "Epoch 31/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0191 - accuracy: 0.5421 - val_loss: 1.0707 - val_accuracy: 0.5235\n",
      "Epoch 32/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.0138 - accuracy: 0.5463 - val_loss: 1.0757 - val_accuracy: 0.5155\n",
      "Epoch 33/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0089 - accuracy: 0.5465 - val_loss: 1.0920 - val_accuracy: 0.5198\n",
      "Epoch 34/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0077 - accuracy: 0.5460 - val_loss: 1.0827 - val_accuracy: 0.5254\n",
      "Epoch 35/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.0047 - accuracy: 0.5562 - val_loss: 1.0997 - val_accuracy: 0.5161\n",
      "Epoch 36/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.9962 - accuracy: 0.5578 - val_loss: 1.1071 - val_accuracy: 0.5217\n",
      "Epoch 37/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.9910 - accuracy: 0.5604 - val_loss: 1.0968 - val_accuracy: 0.5180\n",
      "Epoch 38/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.9932 - accuracy: 0.5541 - val_loss: 1.0928 - val_accuracy: 0.5155\n",
      "Epoch 39/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.9850 - accuracy: 0.5589 - val_loss: 1.1247 - val_accuracy: 0.5229\n",
      "Epoch 40/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.9812 - accuracy: 0.5621 - val_loss: 1.1293 - val_accuracy: 0.5204\n",
      "Epoch 41/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.9735 - accuracy: 0.5592 - val_loss: 1.1087 - val_accuracy: 0.5074\n",
      "Epoch 42/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.9669 - accuracy: 0.5685 - val_loss: 1.1267 - val_accuracy: 0.5211\n",
      "Epoch 43/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.9618 - accuracy: 0.5686 - val_loss: 1.1298 - val_accuracy: 0.5242\n",
      "Epoch 44/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.9568 - accuracy: 0.5666 - val_loss: 1.1588 - val_accuracy: 0.5124\n",
      "Epoch 45/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.9631 - accuracy: 0.5659 - val_loss: 1.1633 - val_accuracy: 0.5149\n",
      "Epoch 46/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.9386 - accuracy: 0.5772 - val_loss: 1.1455 - val_accuracy: 0.5161\n",
      "Epoch 47/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.9359 - accuracy: 0.5824 - val_loss: 1.1738 - val_accuracy: 0.5180\n",
      "Epoch 48/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.9258 - accuracy: 0.5854 - val_loss: 1.1777 - val_accuracy: 0.5043\n",
      "Epoch 49/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.9199 - accuracy: 0.5835 - val_loss: 1.1620 - val_accuracy: 0.5161\n",
      "Epoch 50/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.9123 - accuracy: 0.5851 - val_loss: 1.1807 - val_accuracy: 0.5149\n",
      "Epoch 51/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.9039 - accuracy: 0.5903 - val_loss: 1.2576 - val_accuracy: 0.5056\n",
      "Epoch 52/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.9000 - accuracy: 0.5931 - val_loss: 1.2384 - val_accuracy: 0.4981\n",
      "Epoch 53/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.8867 - accuracy: 0.5951 - val_loss: 1.2464 - val_accuracy: 0.4963\n",
      "Epoch 54/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.8812 - accuracy: 0.6030 - val_loss: 1.3005 - val_accuracy: 0.5112\n",
      "Epoch 55/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.8794 - accuracy: 0.6054 - val_loss: 1.2829 - val_accuracy: 0.5167\n",
      "Epoch 56/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.8684 - accuracy: 0.6119 - val_loss: 1.3167 - val_accuracy: 0.5124\n",
      "Epoch 57/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.8613 - accuracy: 0.6108 - val_loss: 1.2737 - val_accuracy: 0.5025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.8466 - accuracy: 0.6190 - val_loss: 1.2948 - val_accuracy: 0.5056\n",
      "Epoch 59/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.8791 - accuracy: 0.6108 - val_loss: 1.2593 - val_accuracy: 0.5124\n",
      "Epoch 60/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.8363 - accuracy: 0.6266 - val_loss: 1.3305 - val_accuracy: 0.5161\n",
      "Epoch 61/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.8345 - accuracy: 0.6269 - val_loss: 1.3528 - val_accuracy: 0.5136\n",
      "Epoch 62/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.8217 - accuracy: 0.6345 - val_loss: 1.3238 - val_accuracy: 0.4969\n",
      "Epoch 63/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.8137 - accuracy: 0.6353 - val_loss: 1.3882 - val_accuracy: 0.5043\n",
      "Epoch 64/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.8118 - accuracy: 0.6326 - val_loss: 1.4869 - val_accuracy: 0.5074\n",
      "Epoch 65/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.8105 - accuracy: 0.6340 - val_loss: 1.4145 - val_accuracy: 0.5043\n",
      "Epoch 66/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.7884 - accuracy: 0.6422 - val_loss: 1.4724 - val_accuracy: 0.5074\n",
      "Epoch 67/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.7778 - accuracy: 0.6528 - val_loss: 1.4413 - val_accuracy: 0.4882\n",
      "Epoch 68/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.7809 - accuracy: 0.6484 - val_loss: 1.5025 - val_accuracy: 0.4938\n",
      "Epoch 69/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.7886 - accuracy: 0.6466 - val_loss: 1.4488 - val_accuracy: 0.5031\n",
      "Epoch 70/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.7603 - accuracy: 0.6574 - val_loss: 1.5969 - val_accuracy: 0.4919\n",
      "Epoch 71/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.7508 - accuracy: 0.6621 - val_loss: 1.5563 - val_accuracy: 0.4901\n",
      "Epoch 72/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.7602 - accuracy: 0.6577 - val_loss: 1.5550 - val_accuracy: 0.4895\n",
      "Epoch 73/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.7588 - accuracy: 0.6608 - val_loss: 1.6280 - val_accuracy: 0.4926\n",
      "Epoch 74/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.7411 - accuracy: 0.6694 - val_loss: 1.6740 - val_accuracy: 0.4988\n",
      "Epoch 75/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.7259 - accuracy: 0.6731 - val_loss: 1.6814 - val_accuracy: 0.5019\n",
      "Epoch 76/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.7288 - accuracy: 0.6760 - val_loss: 1.7816 - val_accuracy: 0.4926\n",
      "Epoch 77/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.7129 - accuracy: 0.6831 - val_loss: 1.5951 - val_accuracy: 0.4839\n",
      "Epoch 78/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.7192 - accuracy: 0.6757 - val_loss: 1.7523 - val_accuracy: 0.4907\n",
      "Epoch 79/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.7173 - accuracy: 0.6838 - val_loss: 1.6412 - val_accuracy: 0.5012\n",
      "Epoch 80/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.6952 - accuracy: 0.6923 - val_loss: 1.7815 - val_accuracy: 0.4938\n",
      "Epoch 81/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.6846 - accuracy: 0.6934 - val_loss: 1.8537 - val_accuracy: 0.4851\n",
      "Epoch 82/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.6894 - accuracy: 0.6929 - val_loss: 1.8059 - val_accuracy: 0.4845\n",
      "Epoch 83/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.6740 - accuracy: 0.6965 - val_loss: 1.9198 - val_accuracy: 0.4944\n",
      "Epoch 84/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.6694 - accuracy: 0.7000 - val_loss: 1.9278 - val_accuracy: 0.4957\n",
      "Epoch 85/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.6649 - accuracy: 0.7039 - val_loss: 1.9166 - val_accuracy: 0.5006\n",
      "Epoch 86/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.6603 - accuracy: 0.7048 - val_loss: 2.0384 - val_accuracy: 0.4839\n",
      "Epoch 87/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.6603 - accuracy: 0.7106 - val_loss: 1.9546 - val_accuracy: 0.4827\n",
      "Epoch 88/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.6631 - accuracy: 0.7039 - val_loss: 2.0099 - val_accuracy: 0.4740\n",
      "Epoch 89/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.6693 - accuracy: 0.6993 - val_loss: 2.0423 - val_accuracy: 0.4851\n",
      "Epoch 90/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.6525 - accuracy: 0.7036 - val_loss: 2.1227 - val_accuracy: 0.4888\n",
      "Epoch 91/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.6357 - accuracy: 0.7189 - val_loss: 2.0911 - val_accuracy: 0.4938\n",
      "Epoch 92/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.6331 - accuracy: 0.7200 - val_loss: 2.0106 - val_accuracy: 0.4857\n",
      "Epoch 93/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.6217 - accuracy: 0.7262 - val_loss: 2.0082 - val_accuracy: 0.4839\n",
      "Epoch 94/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.6229 - accuracy: 0.7258 - val_loss: 2.1707 - val_accuracy: 0.4882\n",
      "Epoch 95/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.6306 - accuracy: 0.7208 - val_loss: 2.1621 - val_accuracy: 0.5031\n",
      "Epoch 96/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.6263 - accuracy: 0.7214 - val_loss: 2.2503 - val_accuracy: 0.5000\n",
      "Epoch 97/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.6109 - accuracy: 0.7254 - val_loss: 2.1722 - val_accuracy: 0.4715\n",
      "Epoch 98/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.6354 - accuracy: 0.7202 - val_loss: 2.1257 - val_accuracy: 0.4876\n",
      "Epoch 99/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.5980 - accuracy: 0.7360 - val_loss: 2.1833 - val_accuracy: 0.4870\n",
      "Epoch 100/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5763 - accuracy: 0.7386 - val_loss: 2.2581 - val_accuracy: 0.4876\n",
      "Epoch 101/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.6103 - accuracy: 0.7326 - val_loss: 2.2070 - val_accuracy: 0.4802\n",
      "Epoch 102/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.6047 - accuracy: 0.7323 - val_loss: 2.2153 - val_accuracy: 0.4827\n",
      "Epoch 103/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.5952 - accuracy: 0.7332 - val_loss: 2.3036 - val_accuracy: 0.4758\n",
      "Epoch 104/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5804 - accuracy: 0.7420 - val_loss: 2.3882 - val_accuracy: 0.4938\n",
      "Epoch 105/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.5857 - accuracy: 0.7414 - val_loss: 2.3941 - val_accuracy: 0.4950\n",
      "Epoch 106/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5857 - accuracy: 0.7400 - val_loss: 2.3397 - val_accuracy: 0.4851\n",
      "Epoch 107/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.5850 - accuracy: 0.7423 - val_loss: 2.4408 - val_accuracy: 0.4870\n",
      "Epoch 108/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.5558 - accuracy: 0.7519 - val_loss: 2.4832 - val_accuracy: 0.4870\n",
      "Epoch 109/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.5666 - accuracy: 0.7445 - val_loss: 2.4183 - val_accuracy: 0.4851\n",
      "Epoch 110/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5796 - accuracy: 0.7412 - val_loss: 2.4914 - val_accuracy: 0.4820\n",
      "Epoch 111/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5582 - accuracy: 0.7558 - val_loss: 2.4368 - val_accuracy: 0.4919\n",
      "Epoch 112/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.5661 - accuracy: 0.7522 - val_loss: 2.2753 - val_accuracy: 0.4771\n",
      "Epoch 113/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5575 - accuracy: 0.7522 - val_loss: 2.4835 - val_accuracy: 0.4796\n",
      "Epoch 114/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5573 - accuracy: 0.7535 - val_loss: 2.4328 - val_accuracy: 0.4783\n",
      "Epoch 115/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5257 - accuracy: 0.7698 - val_loss: 2.6292 - val_accuracy: 0.4820\n",
      "Epoch 116/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5751 - accuracy: 0.7419 - val_loss: 2.2555 - val_accuracy: 0.4888\n",
      "Epoch 117/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.5338 - accuracy: 0.7588 - val_loss: 2.4620 - val_accuracy: 0.4752\n",
      "Epoch 118/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5133 - accuracy: 0.7688 - val_loss: 2.8090 - val_accuracy: 0.4969\n",
      "Epoch 119/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5318 - accuracy: 0.7608 - val_loss: 2.4952 - val_accuracy: 0.4765\n",
      "Epoch 120/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5365 - accuracy: 0.7577 - val_loss: 2.6655 - val_accuracy: 0.4796\n",
      "Epoch 121/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5452 - accuracy: 0.7563 - val_loss: 2.6692 - val_accuracy: 0.4783\n",
      "Epoch 122/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.5170 - accuracy: 0.7693 - val_loss: 2.7132 - val_accuracy: 0.4876\n",
      "Epoch 123/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5198 - accuracy: 0.7628 - val_loss: 2.8016 - val_accuracy: 0.4851\n",
      "Epoch 124/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5126 - accuracy: 0.7693 - val_loss: 2.7733 - val_accuracy: 0.4703\n",
      "Epoch 125/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4989 - accuracy: 0.7727 - val_loss: 2.9144 - val_accuracy: 0.4758\n",
      "Epoch 126/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.5742 - accuracy: 0.7527 - val_loss: 2.6230 - val_accuracy: 0.4721\n",
      "Epoch 127/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5065 - accuracy: 0.7676 - val_loss: 2.8618 - val_accuracy: 0.4740\n",
      "Epoch 128/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4990 - accuracy: 0.7730 - val_loss: 2.7990 - val_accuracy: 0.4814\n",
      "Epoch 129/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5002 - accuracy: 0.7761 - val_loss: 3.0162 - val_accuracy: 0.4591\n",
      "Epoch 130/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5141 - accuracy: 0.7722 - val_loss: 2.7992 - val_accuracy: 0.4572\n",
      "Epoch 131/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5031 - accuracy: 0.7760 - val_loss: 2.9376 - val_accuracy: 0.4715\n",
      "Epoch 132/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4960 - accuracy: 0.7798 - val_loss: 2.9186 - val_accuracy: 0.4802\n",
      "Epoch 133/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.5076 - accuracy: 0.7760 - val_loss: 2.9246 - val_accuracy: 0.4777\n",
      "Epoch 134/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.5074 - accuracy: 0.7756 - val_loss: 2.9495 - val_accuracy: 0.4765\n",
      "Epoch 135/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4803 - accuracy: 0.7859 - val_loss: 2.9527 - val_accuracy: 0.4845\n",
      "Epoch 136/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4861 - accuracy: 0.7843 - val_loss: 2.9471 - val_accuracy: 0.4833\n",
      "Epoch 137/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4973 - accuracy: 0.7775 - val_loss: 2.9109 - val_accuracy: 0.4709\n",
      "Epoch 138/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4852 - accuracy: 0.7818 - val_loss: 3.0232 - val_accuracy: 0.4622\n",
      "Epoch 139/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4865 - accuracy: 0.7811 - val_loss: 2.8881 - val_accuracy: 0.4783\n",
      "Epoch 140/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.4840 - accuracy: 0.7825 - val_loss: 2.9507 - val_accuracy: 0.4796\n",
      "Epoch 141/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.4964 - accuracy: 0.7839 - val_loss: 3.0169 - val_accuracy: 0.4777\n",
      "Epoch 142/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4767 - accuracy: 0.7870 - val_loss: 3.0997 - val_accuracy: 0.4796\n",
      "Epoch 143/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.4977 - accuracy: 0.7808 - val_loss: 2.8830 - val_accuracy: 0.4709\n",
      "Epoch 144/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.4578 - accuracy: 0.7959 - val_loss: 2.9605 - val_accuracy: 0.4734\n",
      "Epoch 145/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.4692 - accuracy: 0.7876 - val_loss: 3.0358 - val_accuracy: 0.4771\n",
      "Epoch 146/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4837 - accuracy: 0.7794 - val_loss: 3.0304 - val_accuracy: 0.4610\n",
      "Epoch 147/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4598 - accuracy: 0.7897 - val_loss: 3.0546 - val_accuracy: 0.4696\n",
      "Epoch 148/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4732 - accuracy: 0.7883 - val_loss: 3.1102 - val_accuracy: 0.4678\n",
      "Epoch 149/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4568 - accuracy: 0.7928 - val_loss: 3.1454 - val_accuracy: 0.4566\n",
      "Epoch 150/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4470 - accuracy: 0.7990 - val_loss: 3.2110 - val_accuracy: 0.4789\n",
      "Epoch 151/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4538 - accuracy: 0.8006 - val_loss: 3.1673 - val_accuracy: 0.4721\n",
      "Epoch 152/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4820 - accuracy: 0.7905 - val_loss: 3.0323 - val_accuracy: 0.4597\n",
      "Epoch 153/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4878 - accuracy: 0.7814 - val_loss: 3.0419 - val_accuracy: 0.4690\n",
      "Epoch 154/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.4417 - accuracy: 0.8012 - val_loss: 3.1921 - val_accuracy: 0.4653\n",
      "Epoch 155/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.4323 - accuracy: 0.8003 - val_loss: 3.2919 - val_accuracy: 0.4727\n",
      "Epoch 156/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.4487 - accuracy: 0.7952 - val_loss: 3.4051 - val_accuracy: 0.4771\n",
      "Epoch 157/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4674 - accuracy: 0.7925 - val_loss: 3.1734 - val_accuracy: 0.4721\n",
      "Epoch 158/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4384 - accuracy: 0.7980 - val_loss: 3.1664 - val_accuracy: 0.4765\n",
      "Epoch 159/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4540 - accuracy: 0.7953 - val_loss: 3.2841 - val_accuracy: 0.4665\n",
      "Epoch 160/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4481 - accuracy: 0.8020 - val_loss: 3.1882 - val_accuracy: 0.4641\n",
      "Epoch 161/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.4313 - accuracy: 0.8038 - val_loss: 3.2072 - val_accuracy: 0.4808\n",
      "Epoch 162/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4706 - accuracy: 0.7856 - val_loss: 3.0932 - val_accuracy: 0.4734\n",
      "Epoch 163/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4760 - accuracy: 0.7879 - val_loss: 2.9975 - val_accuracy: 0.4517\n",
      "Epoch 164/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.4561 - accuracy: 0.7961 - val_loss: 3.2115 - val_accuracy: 0.4684\n",
      "Epoch 165/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4186 - accuracy: 0.8091 - val_loss: 3.3144 - val_accuracy: 0.4771\n",
      "Epoch 166/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.4044 - accuracy: 0.8209 - val_loss: 3.2128 - val_accuracy: 0.4771\n",
      "Epoch 167/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.4181 - accuracy: 0.8164 - val_loss: 3.2705 - val_accuracy: 0.4696\n",
      "Epoch 168/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4365 - accuracy: 0.8023 - val_loss: 3.4521 - val_accuracy: 0.4721\n",
      "Epoch 169/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4140 - accuracy: 0.8156 - val_loss: 3.6240 - val_accuracy: 0.4808\n",
      "Epoch 170/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4152 - accuracy: 0.8139 - val_loss: 3.4449 - val_accuracy: 0.4857\n",
      "Epoch 171/250\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.4374 - accuracy: 0.8024 - val_loss: 3.6918 - val_accuracy: 0.4665\n",
      "Epoch 172/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4652 - accuracy: 0.7938 - val_loss: 3.2270 - val_accuracy: 0.4796\n",
      "Epoch 173/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4517 - accuracy: 0.7956 - val_loss: 3.4278 - val_accuracy: 0.4727\n",
      "Epoch 174/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.4148 - accuracy: 0.8107 - val_loss: 3.3700 - val_accuracy: 0.4765\n",
      "Epoch 175/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3986 - accuracy: 0.8179 - val_loss: 3.8462 - val_accuracy: 0.4703\n",
      "Epoch 176/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4097 - accuracy: 0.8162 - val_loss: 3.6266 - val_accuracy: 0.4690\n",
      "Epoch 177/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.4048 - accuracy: 0.8162 - val_loss: 3.6871 - val_accuracy: 0.4659\n",
      "Epoch 178/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.4164 - accuracy: 0.8113 - val_loss: 3.5728 - val_accuracy: 0.4827\n",
      "Epoch 179/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4994 - accuracy: 0.7843 - val_loss: 3.4275 - val_accuracy: 0.4727\n",
      "Epoch 180/250\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.4089 - accuracy: 0.8133 - val_loss: 3.6129 - val_accuracy: 0.4802\n",
      "Epoch 181/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.4133 - accuracy: 0.8139 - val_loss: 3.6437 - val_accuracy: 0.4665\n",
      "Epoch 182/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4047 - accuracy: 0.8161 - val_loss: 3.6516 - val_accuracy: 0.4696\n",
      "Epoch 183/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3932 - accuracy: 0.8192 - val_loss: 3.7102 - val_accuracy: 0.4647\n",
      "Epoch 184/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3732 - accuracy: 0.8293 - val_loss: 3.8026 - val_accuracy: 0.4653\n",
      "Epoch 185/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4033 - accuracy: 0.8159 - val_loss: 4.0263 - val_accuracy: 0.4653\n",
      "Epoch 186/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.4922 - accuracy: 0.7947 - val_loss: 2.9533 - val_accuracy: 0.4715\n",
      "Epoch 187/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4100 - accuracy: 0.8172 - val_loss: 3.5442 - val_accuracy: 0.4665\n",
      "Epoch 188/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.4003 - accuracy: 0.8226 - val_loss: 3.6573 - val_accuracy: 0.4765\n",
      "Epoch 189/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4137 - accuracy: 0.8159 - val_loss: 3.6225 - val_accuracy: 0.4591\n",
      "Epoch 190/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4135 - accuracy: 0.8102 - val_loss: 3.5032 - val_accuracy: 0.4603\n",
      "Epoch 191/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3886 - accuracy: 0.8234 - val_loss: 3.7599 - val_accuracy: 0.4641\n",
      "Epoch 192/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3765 - accuracy: 0.8279 - val_loss: 3.8890 - val_accuracy: 0.4647\n",
      "Epoch 193/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3891 - accuracy: 0.8229 - val_loss: 3.8053 - val_accuracy: 0.4504\n",
      "Epoch 194/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.3846 - accuracy: 0.8244 - val_loss: 3.8641 - val_accuracy: 0.4647\n",
      "Epoch 195/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.4209 - accuracy: 0.8158 - val_loss: 3.7354 - val_accuracy: 0.4715\n",
      "Epoch 196/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4140 - accuracy: 0.8172 - val_loss: 3.7703 - val_accuracy: 0.4634\n",
      "Epoch 197/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.3952 - accuracy: 0.8221 - val_loss: 3.7480 - val_accuracy: 0.4610\n",
      "Epoch 198/250\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.3683 - accuracy: 0.8294 - val_loss: 4.0737 - val_accuracy: 0.4585\n",
      "Epoch 199/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.3759 - accuracy: 0.8310 - val_loss: 3.8851 - val_accuracy: 0.4634\n",
      "Epoch 200/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3762 - accuracy: 0.8330 - val_loss: 3.9121 - val_accuracy: 0.4653\n",
      "Epoch 201/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.4065 - accuracy: 0.8203 - val_loss: 3.9214 - val_accuracy: 0.4653\n",
      "Epoch 202/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4153 - accuracy: 0.8093 - val_loss: 3.7233 - val_accuracy: 0.4616\n",
      "Epoch 203/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3983 - accuracy: 0.8210 - val_loss: 3.6136 - val_accuracy: 0.4665\n",
      "Epoch 204/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.4237 - accuracy: 0.8114 - val_loss: 3.7408 - val_accuracy: 0.4709\n",
      "Epoch 205/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.4017 - accuracy: 0.8178 - val_loss: 3.7450 - val_accuracy: 0.4796\n",
      "Epoch 206/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3882 - accuracy: 0.8227 - val_loss: 3.7354 - val_accuracy: 0.4622\n",
      "Epoch 207/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3563 - accuracy: 0.8331 - val_loss: 3.8563 - val_accuracy: 0.4715\n",
      "Epoch 208/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3554 - accuracy: 0.8385 - val_loss: 3.8151 - val_accuracy: 0.4622\n",
      "Epoch 209/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3640 - accuracy: 0.8305 - val_loss: 3.8323 - val_accuracy: 0.4647\n",
      "Epoch 210/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.3868 - accuracy: 0.8209 - val_loss: 3.7703 - val_accuracy: 0.4771\n",
      "Epoch 211/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3752 - accuracy: 0.8268 - val_loss: 3.9154 - val_accuracy: 0.4715\n",
      "Epoch 212/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.4127 - accuracy: 0.8153 - val_loss: 3.3472 - val_accuracy: 0.4765\n",
      "Epoch 213/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.4150 - accuracy: 0.8145 - val_loss: 4.0373 - val_accuracy: 0.4734\n",
      "Epoch 214/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.3930 - accuracy: 0.8206 - val_loss: 3.7705 - val_accuracy: 0.4610\n",
      "Epoch 215/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.3678 - accuracy: 0.8336 - val_loss: 3.9544 - val_accuracy: 0.4647\n",
      "Epoch 216/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3639 - accuracy: 0.8356 - val_loss: 4.0506 - val_accuracy: 0.4758\n",
      "Epoch 217/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3795 - accuracy: 0.8285 - val_loss: 4.1639 - val_accuracy: 0.4554\n",
      "Epoch 218/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3804 - accuracy: 0.8306 - val_loss: 4.0063 - val_accuracy: 0.4715\n",
      "Epoch 219/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4038 - accuracy: 0.8231 - val_loss: 3.9281 - val_accuracy: 0.4511\n",
      "Epoch 220/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.4069 - accuracy: 0.8200 - val_loss: 3.8499 - val_accuracy: 0.4579\n",
      "Epoch 221/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3765 - accuracy: 0.8320 - val_loss: 3.8858 - val_accuracy: 0.4734\n",
      "Epoch 222/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3541 - accuracy: 0.8389 - val_loss: 4.1462 - val_accuracy: 0.4727\n",
      "Epoch 223/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3889 - accuracy: 0.8306 - val_loss: 3.6867 - val_accuracy: 0.4634\n",
      "Epoch 224/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3494 - accuracy: 0.8393 - val_loss: 3.9727 - val_accuracy: 0.4845\n",
      "Epoch 225/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3373 - accuracy: 0.8426 - val_loss: 4.1282 - val_accuracy: 0.4634\n",
      "Epoch 226/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3670 - accuracy: 0.8333 - val_loss: 3.9824 - val_accuracy: 0.4709\n",
      "Epoch 227/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3851 - accuracy: 0.8252 - val_loss: 3.8848 - val_accuracy: 0.4777\n",
      "Epoch 228/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3701 - accuracy: 0.8336 - val_loss: 3.9396 - val_accuracy: 0.4783\n",
      "Epoch 229/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3551 - accuracy: 0.8331 - val_loss: 4.4463 - val_accuracy: 0.4672\n",
      "Epoch 230/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3672 - accuracy: 0.8271 - val_loss: 3.8742 - val_accuracy: 0.4591\n",
      "Epoch 231/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3933 - accuracy: 0.8313 - val_loss: 3.7296 - val_accuracy: 0.4789\n",
      "Epoch 232/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3666 - accuracy: 0.8333 - val_loss: 3.9746 - val_accuracy: 0.4672\n",
      "Epoch 233/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3775 - accuracy: 0.8317 - val_loss: 3.7476 - val_accuracy: 0.4641\n",
      "Epoch 234/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.3595 - accuracy: 0.8344 - val_loss: 4.0018 - val_accuracy: 0.4603\n",
      "Epoch 235/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3580 - accuracy: 0.8379 - val_loss: 3.9540 - val_accuracy: 0.4684\n",
      "Epoch 236/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.3531 - accuracy: 0.8435 - val_loss: 4.0827 - val_accuracy: 0.4690\n",
      "Epoch 237/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.3882 - accuracy: 0.8282 - val_loss: 4.1586 - val_accuracy: 0.4511\n",
      "Epoch 238/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3647 - accuracy: 0.8337 - val_loss: 4.1494 - val_accuracy: 0.4585\n",
      "Epoch 239/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3352 - accuracy: 0.8424 - val_loss: 4.4113 - val_accuracy: 0.4758\n",
      "Epoch 240/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3303 - accuracy: 0.8514 - val_loss: 4.2312 - val_accuracy: 0.4610\n",
      "Epoch 241/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3335 - accuracy: 0.8446 - val_loss: 4.2041 - val_accuracy: 0.4703\n",
      "Epoch 242/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3479 - accuracy: 0.8390 - val_loss: 4.1251 - val_accuracy: 0.4622\n",
      "Epoch 243/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3689 - accuracy: 0.8339 - val_loss: 3.6720 - val_accuracy: 0.4535\n",
      "Epoch 244/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3749 - accuracy: 0.8344 - val_loss: 4.1041 - val_accuracy: 0.4802\n",
      "Epoch 245/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3567 - accuracy: 0.8364 - val_loss: 4.3044 - val_accuracy: 0.4709\n",
      "Epoch 246/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3615 - accuracy: 0.8368 - val_loss: 4.0082 - val_accuracy: 0.4548\n",
      "Epoch 247/250\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3388 - accuracy: 0.8390 - val_loss: 4.5053 - val_accuracy: 0.4653\n",
      "Epoch 248/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3680 - accuracy: 0.8392 - val_loss: 4.0566 - val_accuracy: 0.4709\n",
      "Epoch 249/250\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.3641 - accuracy: 0.8382 - val_loss: 3.9327 - val_accuracy: 0.4665\n",
      "Epoch 250/250\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 0.3365 - accuracy: 0.8409 - val_loss: 4.2532 - val_accuracy: 0.4647\n",
      "253/253 [==============================] - 1s 4ms/step - loss: 1.0828 - accuracy: 0.7861\n",
      "Test Loss: 1.082831621170044\n",
      "Test Accuracy: 0.7860684394836426\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the neural network model\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(22,)),      # Update input shape to (22,)\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use 'sparse_categorical_crossentropy' for integer labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=250, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(x_train, y_train)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58ca0c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 9.8075 - accuracy: 0.3194\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053c559e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
